- ホップフィールドネットワーク (Hopfield Network)
	- 全結合型の[[ニューラルネットワーク]]
	- ![[Pasted image 20250605192652.png|200]]
- 構造
	- [[ニューロン]] $N$ 個とする。自己結合も想定すると結合は $N\times N$ 個ある
	- ニューロン $i$ から $j$ への結合重みを $w_{ij}$ とすると重み行列は $W \in ℝ^{N \times N}$ で表せる
	- 各ニューロンは結合している他のニューロンからの入力を合わせて何らかの値を計算し $1$ か $-1$ の値を保持
	- 出力は $N$ 次元ベクトル $y\in\{-1,1\}^N$ 
- [[学習]]
	- [[記憶]]するパターンを $x^i\in\{-1,1\}^N\ (i=1,2,...,Q)$ の $Q$ 個とする
	- これらに対し重み行列を$$W = \frac{1}{Q}\sum_{q=1}^{Q} x^q (x^q)^T$$ と定義する
	- 定義上 $w_{ij}=w_{ji}$ 
	- これらは固定で、[[想起]]時には更新されない
- [[想起]]
	- 元の記憶したパターンに[[ノイズ]]が加わったような入力から元のパターンを想起
	- パターンのいずれかにノイズを加えたテスト入力 $x=x_i+\epsilon\in ℝ^{N}$ を用意する
	- 各ニューロンの値を $x$ の各値に初期化し値を更新 $${\begin{align}
y_i(t) &= \sum_{j=1}^{N} w_{ij} * x_j(t)\\
x_i(t+1) &= {\rm sgn}(y_i(t) - \theta_i)
\end{align}
}$$
	- $\theta$ は閾値で、$\rm sgn$ は符号をみて $-1,0,+1$ のいずれかを取る関数
	- このネットワークのエネルギーは $$E(t) = -\frac{1}{2} \sum_{i \neq j} w_{ij}x_i(t)x_j(t) + \sum_i \theta_i x_i(t)$$
		- 各 $x_i$ についてみると $$-\left(\frac{1}{2} \sum_{j} w_{ij}x_j(t) - \theta_i \right)x_i(t) + (\textrm{const. with respect to }x_i)$$と書けるので、$y_i−θ_i$ の符号によって $x_i$ を更新することで更新のたびに $E$ は単調減少する
		- $E$ が収束した点が想起の完了（収束することが知られている）
	
```python
import numpy as np
import copy

class Hopfield:
    """
    patterns : list[np.ndarray]  # 各要素は +1/-1 の 2D 正方形 (sqrt(N) * sqrt(N)) 配列
    sync     : True=同期更新 / False=非同期更新
    max_iter : 収束判定の上限ステップ
    """
    def __init__(self, patterns, sync=False, max_iter=50):
        self.patterns = patterns
        self.P = np.stack([p.flatten() for p in patterns])
        self.N = self.P.shape[1] # n * n
        self.sync = sync
        self.max_iter = max_iter
        self.W = self.train()

    def train(self):
        """
        重み行列 W を学習する
        """
        W = (self.P.T @ self.P) / self.N 
        np.fill_diagonal(W, 0)
        return W
    
    def add_noise(self, vector, ratio):
        """
        vector に反転させる割合 ratio のノイズを加える
        ----------------
        vector : 1D (+1/-1) 状態  # N 次元ベクトル
        ratio  : 反転させる割合 (0 - 1)
        """
        v = vector.copy()
        n_flip = int(self.N * ratio)
        idx = np.random.choice(self.N, n_flip, replace=False)
        v[idx] *= -1
        return v
    
    def recall(self, state):
        """
        学習済みの重み行列 W を用いて状態 state を再帰する
        ----------------
        state : 1D (+1/-1) 状態  # N 次元ベクトル
        """
        state = state.copy()
        for _ in range(self.max_iter):
            if self.sync:
                new_state = np.sign(self.W @ state)
            else:
                idx = np.random.permutation(self.N)
                new_state = state.copy()
                for i in idx:
                    new_state[i] = np.sign(self.W[i] @ state)

            if np.array_equal(new_state, state):
                break
            state = new_state
        
        return state
    

    @staticmethod
    def similarity(v1, v2):
        return (v1 == v2).mean()

    @staticmethod
    def accuracy(v1, v2):
        return 1 if np.array_equal(v1, v2) else 0```