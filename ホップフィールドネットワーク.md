- ホップフィールドネットワーク (Hopfield Network)
	- 全結合型の[[ニューラルネットワーク]]
	- ![[Pasted image 20250605192652.png|200]]
- 構造
	- [[ニューロン]] $N$ 個とする。自己結合も想定すると結合は $N\times N$ 個ある
	- ニューロン $i$ から $j$ への結合重みを $w_{ij}$ とすると重み行列は $W \in ℝ^{N \times N}$ で表せる
	- 各ニューロンは結合している他のニューロンからの入力を合わせて何らかの値を計算し $1$ か $-1$ の値を保持
	- 出力は $N$ 次元ベクトル $y\in\{-1,1\}^N$ 
- [[学習]]
	- [[記憶]]するパターンを $x^i\in\{-1,1\}^N\ (i=1,2,...,Q)$ の $Q$ 個とする
	- これらに対し重み行列を$$W = \frac{1}{Q}\sum_{q=1}^{Q} x^q (x^q)^T$$ と定義する
	- 定義上 $w_{ij}=w_{ji}$ 
	- これらは固定で、[[想起]]時には更新されない
- [[想起]]
	- 元の記憶したパターンに[[ノイズ]]が加わったような入力から元のパターンを想起
	- パターンのいずれかにノイズを加えたテスト入力 $x=x_i+\epsilon\in ℝ^{N}$ を用意する
	- 各ニューロンの値を $x$ の各値に初期化し値を更新 $${\begin{align}
y_i(t) &= \sum_{j=1}^{N} w_{ij} * x_j(t)\\
x_i(t+1) &= {\rm sgn}(y_i(t) - \theta_i)
\end{align}
}$$
	- $\theta$ は閾値で、$\rm sgn$ は符号をみて $-1,0,+1$ のいずれかを取る関数
	- このネットワークのエネルギーは $$E(t) = -\frac{1}{2} \sum_{i \neq j} w_{ij}x_i(t)x_j(t) + \sum_i \theta_i x_i(t)$$
		- 各 $x_i$ についてみると $$-\bigl(\frac{1}{2} \sum_{j} w_{ij}x_j(t) - \theta_i \bigl)x_i(t) + const. $$